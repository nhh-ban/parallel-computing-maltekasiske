stations[[1]] %>%
map(as_tibble) %>%
list_rbind() %>%
mutate(latestData = map_chr(latestData, 1, .default=NA_character_)) %>%
mutate(latestData = as.Date(latestData))
stations[[1]] %>%
map(as_tibble) %>%
list_rbind() %>%
mutate(latestData = map_chr(latestData, 1, .default = NA_character_)) %>%
mutate(latestData = as_datetime(latestData, tz = "Europe/Berlin"))
stations[[1]] |>
map(as_tibble) |>
list_rbind() |>
mutate(latestData = map_chr(latestData, 1, .default = ""))  |>
mutate(latestData = as_datetime(latestData, tz = "Europe/Berlin"))  |>
mutate(location = map(location, unlist)) |>
mutate(
lat = map_dbl(location, "latLon.lat"),
lon = map_dbl(location, "latLon.lon")
) %>%
select(-location)
stations[[1]] |>
map(as_tibble) |>
list_rbind() |>
mutate(latestData = map_chr(latestData, 1, .default = NA_character_)) |>
mutate(latestData = as_datetime(latestData, tz = "Europe/Berlin"))  |>
unnest_wider(location) |>
unnest_wider(latLon)
library(tictoc)
# We can use tictoc to time a function..:
tic()
Sys.sleep(1)
toc()
# timer.r
source("1_hw4_solution_original.R")
setwd("C:/Users/Malte Kasiske/Documents/Bildung/Technische Universität Berlin/Master/Auslandssemester/Courses/BAN400/Assignments/Assignment 8 - Parallel Computing/parallel-computing-maltekasiske")
# timer.r
source("1_hw4_solution_original.R")
# timer.r
source("/scripts/1_hw4_solution_original.R")
# timer.r
source("scripts/1_hw4_solution_original.R")
# timer.r
source("scripts/1_hw4_solution_original.R")
source("scripts/2_hw4_solution_parallel_computing.R")
source("scripts/3_hw4_solution_multiple_cores.R")
setwd("~/Bildung/Technische Universität Berlin/Master/Auslandssemester/Courses/BAN400/Assignments/Assignment 8 - Parallel Computing/parallel-computing-maltekasiske")
# timer.r
source("scripts/1_hw4_solution_original.R")
source("scripts/2_hw4_solution_parallel_computing.R")
source("scripts/3_hw4_solution_multiple_cores.R")
# timer.r
source("scripts/1_hw4_solution_original.R")
source("scripts/2_hw4_solution_parallel_computing.R")
source("scripts/3_hw4_solution_multiple_cores.R")
library(tictoc)
# Time the original script
tic("Original")
source("scripts/1_hw4_solution_original.R")
toc()
# Time the script with parallel computing
tic("Parallel computing")
source("scripts/2_hw4_solution_parallel_computing.R")
library(tictoc)
# Time the original script
tic("Original")
source("scripts/1_hw4_solution_original.R")
toc()
# Time the script with parallel computing
tic("Parallel computing")
source("scripts/2_hw4_solution_parallel_computing.R")
cat("\014")
library(tictoc)
# Time the original script
tic("Original")
source("scripts/1_hw4_solution_original.R")
toc()
# Time the script with parallel computing
tic("Parallel computing")
source("scripts/2_hw4_solution_parallel_computing.R")
cat("\014")
library(tictoc)
# Time the original script
tic("Original")
source("scripts/1_hw4_solution_original.R")
toc()
# Time the script with parallel computing
tic("Parallel computing")
source("scripts/2_hw4_solution_parallel_computing.R")
# Assignment 1:
library(tweedie)
library(ggplot2)
library(foreach)
library(doParallel)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
MTweedieTests <-
function(N, M, sig, cores = 1){
cl <- makeCluster(cores)
registerDoParallel(cl)
results <- foreach(i = 1:N, .combine = 'c') %dopar% {
simTweedieTest(N = N)
}
stopCluster(cl)
sum(results < sig)/M
}
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA
)
for(i in 1:nrow(df)){
df$share_reject[i] <-
MTweedieTests(
N = df$N[i],
M = df$M[i],
sig = 0.05,
cores = 2
)
}
# Assignment 1:
library(tweedie)
library(ggplot2)
library(foreach)
library(doParallel)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
MTweedieTests <-
function(N, M, sig, cores = 1){
cl <- makeCluster(cores)
registerDoParallel(cl)
results <- foreach(i = 1:N, .combine = 'c') %dopar% {
simTweedieTest(N = N)
}
stopCluster(cl)
sum(results < sig)/M
}
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA
)
for(i in 1:nrow(df)){
df$share_reject[i] <-
MTweedieTests(
N = df$N[i],
M = df$M[i],
sig = 0.05,
cores = 2
)
}
# Assignment 1:
library(tweedie)
library(ggplot2)
library(foreach)
library(doParallel)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Assignment 2:
MTweedieTests <-
function(N, M, sig, cores = 1){
cl <- makeCluster(cores)
registerDoParallel(cl)
results <- foreach(i = 1:N, .combine = 'c') %dopar% {
simTweedieTest(N = N)
}
stopCluster(cl)
sum(results < sig)/M
}
# Assignment 3:
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA)
for(i in 1:nrow(df)){
df$share_reject[i] <-
MTweedieTests(
N = df$N[i],
M = df$M[i],
sig = 0.05,
cores = min(parallel::detectCores(), 10)
)
}
# Assignment 1:
library(tweedie)
library(ggplot2)
library(foreach)
library(doParallel)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Assignment 2:
MTweedieTests <-
function(N, M, sig, cores = 1){
cl <- makeCluster(cores)
registerDoParallel(cl)
# Export the simTweedieTest function to workers
clusterExport(cl, "simTweedieTest")
results <- foreach(i = 1:N, .combine = 'c') %dopar% {
simTweedieTest(N = N)
}
stopCluster(cl)
sum(results < sig)/M
}
# Assignment 3:
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA)
for(i in 1:nrow(df)){
df$share_reject[i] <-
MTweedieTests(
N = df$N[i],
M = df$M[i],
sig = 0.05,
cores = min(parallel::detectCores(), 10)
)
}
# Assignment 1:
library(tweedie)
library(ggplot2)
library(foreach)
library(doParallel)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Assignment 2:
MTweedieTests <-
function(N, M, sig, cores = 1){
cl <- makeCluster(cores)
registerDoParallel(cl)
# Export the tweedie package and rtweedie function to workers
clusterExport(cl, "tweedie")
clusterEvalQ(cl, library(tweedie))
results <- foreach(i = 1:N, .combine = 'c') %dopar% {
simTweedieTest(N = N)
}
stopCluster(cl)
sum(results < sig)/M
}
# Assignment 3:
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA)
for(i in 1:nrow(df)){
df$share_reject[i] <-
MTweedieTests(
N = df$N[i],
M = df$M[i],
sig = 0.05,
cores = min(parallel::detectCores(), 10)
)
}
# Assignment 1:
library(tweedie)
library(ggplot2)
library(foreach)
library(doParallel)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Assignment 2:
MTweedieTests <-
function(N, M, sig, cores = 1){
cl <- makeCluster(cores)
registerDoParallel(cl)
results <- foreach(i = 1:N, .combine = 'c') %dopar% {
simTweedieTest(N = N)
}
stopCluster(cl)
sum(results < sig)/M
}
# Assignment 3:
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA
)
for(i in 1:nrow(df)){
df$share_reject[i] <-
MTweedieTests(
N = df$N[i],
M = df$M[i],
sig = 0.05,
cores = min(parallel::detectCores(), 10)
)
}
# Assignment 1:
library(tweedie)
library(ggplot2)
library(foreach)
library(doParallel)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Assignment 2:
MTweedieTests <-
function(N, M, sig, cores = 1){
cl <- makeCluster(cores)
registerDoParallel(cl)
results <- foreach(i = 1:N, .combine = 'c') %dopar% {
simTweedieTest(N = N)
}
stopCluster(cl)
sum(results < sig)/M
}
# Assignment 3:
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA
)
for(i in 1:nrow(df)){
df$share_reject[i] <-
MTweedieTests(
N = df$N[i],
M = df$M[i],
sig = 0.05,
cores = min(parallel::detectCores(), 10)
)
}
# Assignment 1:
library(tweedie)
library(ggplot2)
simTweedieTest <-
function(N){
t.test(
rtweedie(N, mu=10000, phi=100, power=1.9),
mu=10000
)$p.value
}
# Assignment 2:
MTweedieTests <-
function(N,M,sig){
sum(replicate(M,simTweedieTest(N)) < sig)/M
}
# Assignment 3:
df <-
expand.grid(
N = c(10,100,1000,5000, 10000),
M = 1000,
share_reject = NA)
library(foreach)
library(doParallel)
# Create a parallel backend with multiple cores (adjust 'cores' as needed)
cl <- makeCluster(detectCores())
registerDoParallel(cl)
# Parallel loop using foreach
results <- foreach(i = 1:nrow(df), .packages = c("tweedie", "ggplot2")) %dopar% {
MTweedieTests(N = df$N[i], M = df$M[i], sig = 0.05)
}
# Stop the parallel backend
stopCluster(cl)
# Assign the results to df
df$share_reject <- results
## Assignemnt 4
# This is one way of solving it - maybe you have a better idea?
# First, write a function for simulating data, where the "type"
# argument controls the distribution. We also need to ensure
# that the mean "mu" is the same for both distributions. This
# argument will also be needed in the t-test for the null
# hypothesis. Therefore, if we hard code in a value here
# we may later have an inconsistency between the mean of the
# distributions and the t-test. So, we add it as an explicit
# argument:
library(magrittr)
library(tidyverse)
simDat <-
function(N, type, mu) {
if (type == "tweedie") {
return(rtweedie(
N,
mu = mu,
phi = 100,
power = 1.9
))
}
if (type == "normal") {
return(rnorm(N, mean = mu))
}
else{
stop("invalid distribution")
}
}
# Next, the test. Note, we use mu two places:
# both for the data simulation and as the null.
simTest <-
function(N, type, mu) {
t.test(simDat(N = N,
type = type,
mu = mu),
mu = mu)$p.value
}
# Running many tests is almost the same as before.
# Here the mean is hard coded in, as we're not
# going to change it.
MTests <-
function(N, M, type, sig) {
sum(replicate(M,
simTest(
N = N,
type =
type,
mu =
10000
)) < sig) / M
}
# We can now repeat the same analysis as before,
# but for both the tweedie and the normal:
df <-
expand.grid(
N = c(10, 100, 1000, 5000),
M = 1000,
type = c("tweedie", "normal"),
share_reject = NA
) %>%
as_tibble()
for (i in 1:nrow(df)) {
print(i)
df$share_reject[i] <-
MTests(df$N[i],
df$M[i],
df$type[i],
.05)
}
# As you see, with normally distributed data, N can
# be very small and the t-test is fine. With a tweedie,
# "large enough" can be many thousands. If we try
# different distributions or parameterizations, we might
# also get different results.
df %>%
ggplot2::ggplot(aes(x = log(N), y = share_reject, col = type)) +
geom_line() +
geom_hline(yintercept = .05) +
theme_bw()
library(tictoc)
# Time the original script
tic("Original")
source("scripts/1_hw4_solution_original.R")
toc()
# Time the script with parallel computing
tic("Parallel computing")
source("scripts/2_hw4_solution_parallel_computing.R")
toc()
# Time the script with rewritten MTweedieTests function to split the
# M simulations in more than one core
tic("Multiple cores")
source("scripts/3_hw4_solution_multiple_cores.R")
toc()
library(tictoc)
# Time the original script
tic("Original")
source("scripts/1_hw4_solution_original.R")
toc()
# Time the script with parallel computing
tic("Parallel computing")
source("scripts/2_hw4_solution_parallel_computing.R")
toc()
# Time the script with rewritten MTweedieTests function to split the
# M simulations in more than one core
tic("Multiple cores")
source("scripts/3_hw4_solution_multiple_cores.R")
toc()
############ Results ############
# Original: 62.63 sec
# Parallel: 50.61 sec
# Multiple cores: 62.16 sec
# The multiple cores script (62.16 sec) might be almost as slow as the original
# one because of one of the two reasons:
# 1. Communication overhead: Splitting simulations across multiple cores may
# introduce communication overhead, slowing down the process.
# 2. Non-parallelizable sections: Some parts of the script can't be parallelized
# and must be executed sequentially, limiting potential speedup.
